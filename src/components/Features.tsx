'use client'

import { motion } from 'framer-motion'

const features = [
  {
    title: 'Real-Time Signal Processing',
    description: 'Process magnetic signals from NV centers in real-time using advanced CNN architecture',
    icon: 'âš¡'
  },
  {
    title: 'Heatmap Denoising',
    description: 'Distinguish true neural magnetic signals from background noise and motion artifacts',
    icon: 'ðŸ”¬'
  },
  {
    title: 'Spatial Feature Extraction',
    description: 'Learn local gradients, polarity shifts, and clustered flux regions in magnetic heatmaps',
    icon: 'ðŸ“¡'
  },
  {
    title: 'Current Direction Inference',
    description: 'Predict vector fields that estimate neural current flow direction and magnitude',
    icon: 'ðŸ§ '
  }
]

export default function Features() {
  return (
    <section className="py-20 px-4">
      <div className="section-container">
        <motion.div
          className="text-center mb-16"
          initial={{ opacity: 0, y: -20 }}
          whileInView={{ opacity: 1, y: 0 }}
          viewport={{ once: true }}
          transition={{ duration: 0.6 }}
        >
          <h2 className="text-4xl md:text-5xl font-bold gradient-text mb-4">
            Advanced CNN Architecture
          </h2>
          <p className="text-gray-400 text-lg max-w-2xl mx-auto">
            Leveraging convolutional neural networks to unlock room-temperature quantum sensing
          </p>
        </motion.div>

        <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
          {features.map((feature, idx) => (
            <motion.div
              key={idx}
              className="glass-dark p-8 rounded-xl hover:border-quantum-purple transition-all duration-300"
              initial={{ opacity: 0, y: 20 }}
              whileInView={{ opacity: 1, y: 0 }}
              viewport={{ once: true }}
              transition={{ duration: 0.5, delay: idx * 0.1 }}
              whileHover={{ y: -5 }}
            >
              <div className="text-5xl mb-4">{feature.icon}</div>
              <h3 className="text-xl font-bold text-white mb-3">{feature.title}</h3>
              <p className="text-gray-400 leading-relaxed">{feature.description}</p>
            </motion.div>
          ))}
        </div>

        <motion.div
          className="mt-16 p-8 glass-dark rounded-xl border-l-4 border-quantum-purple"
          initial={{ opacity: 0, x: -20 }}
          whileInView={{ opacity: 1, x: 0 }}
          viewport={{ once: true }}
          transition={{ duration: 0.6 }}
        >
          <h3 className="text-2xl font-bold text-white mb-4">How It Works</h3>
          <div className="space-y-4 text-gray-300">
            <p>
              <span className="font-semibold text-quantum-cyan">1. Signal Detection:</span> NV centers in diamond detect ultra-weak magnetic fields generated by neural action potentials.
            </p>
            <p>
              <span className="font-semibold text-quantum-cyan">2. Heatmap Formation:</span> Sensor arrays produce magnetic field heatmaps representing spatial flux patterns above the culture.
            </p>
            <p>
              <span className="font-semibold text-quantum-cyan">3. CNN Feature Learning:</span> Stacked 3x3 convolutions with ReLU extract gradients, polarity changes, and localized flux signatures.
            </p>
            <p>
              <span className="font-semibold text-quantum-cyan">4. Inverse Inference:</span> The network outputs neuron detection heatmaps and current-direction vector fields for interpretability.
            </p>
            <p>
              This inverse-model learning pipeline maps magnetic field distributions to likely neuron locations without explicitly solving ill-posed analytical equations.
            </p>
            <p>
              Direction inference uses continuous vector-field regression with cosine-similarity loss to stabilize flow orientation while preserving magnitude.
            </p>
          </div>
        </motion.div>
      </div>
    </section>
  )
}
